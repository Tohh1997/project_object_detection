{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'centernet_hourglass104' \n",
    "PRETRAINED_MODEL_NAME = 'centernet_hg104_1024x1024_kpts_coco17_tpu-32'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_hg104_1024x1024_kpts_coco17_tpu-32.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('TensorFlow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('TensorFlow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('TensorFlow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('TensorFlow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('TensorFlow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('TensorFlow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('TensorFlow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('TensorFlow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('TensorFlow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('TensorFlow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('TensorFlow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH':os.path.join('TensorFlow','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('TensorFlow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wget\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-01 00:15:57--  http://download.tensorflow.org/models/object_detection/tf2/20200711/centernet_hg104_1024x1024_kpts_coco17_tpu-32.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 172.217.19.80, 2a00:1450:4005:80b::2010\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|172.217.19.80|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1453412998 (1,4G) [application/x-tar]\n",
      "Saving to: ‘centernet_hg104_1024x1024_kpts_coco17_tpu-32.tar.gz’\n",
      "\n",
      "centernet_hg104_102 100%[===================>]   1,35G  52,3MB/s    in 27s     \n",
      "\n",
      "2022-12-01 00:16:25 (51,1 MB/s) - ‘centernet_hg104_1024x1024_kpts_coco17_tpu-32.tar.gz’ saved [1453412998/1453412998]\n",
      "\n",
      "centernet_hg104_1024x1024_kpts_coco17_tpu-32/\n",
      "centernet_hg104_1024x1024_kpts_coco17_tpu-32/checkpoint/\n",
      "centernet_hg104_1024x1024_kpts_coco17_tpu-32/checkpoint/ckpt-0.data-00000-of-00001\n",
      "centernet_hg104_1024x1024_kpts_coco17_tpu-32/checkpoint/checkpoint\n",
      "centernet_hg104_1024x1024_kpts_coco17_tpu-32/checkpoint/ckpt-0.index\n",
      "centernet_hg104_1024x1024_kpts_coco17_tpu-32/pipeline.config\n",
      "centernet_hg104_1024x1024_kpts_coco17_tpu-32/saved_model/\n",
      "centernet_hg104_1024x1024_kpts_coco17_tpu-32/saved_model/saved_model.pb\n",
      "centernet_hg104_1024x1024_kpts_coco17_tpu-32/saved_model/variables/\n",
      "centernet_hg104_1024x1024_kpts_coco17_tpu-32/saved_model/variables/variables.data-00000-of-00001\n",
      "centernet_hg104_1024x1024_kpts_coco17_tpu-32/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "#Download the pre_trained_model and move it to \\Tensorflow\\workspace\\pre-trained-models, then unzip it.\n",
    "if os.name =='posix':\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "if os.name == 'nt':\n",
    "    wget.download(PRETRAINED_MODEL_URL)\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME) = 'Tensorflow\\\\workspace\\\\annotations\\\\label_map.pbtxt \n",
    "#--> already done, also don't need to do it again!\n",
    "\n",
    "#labels = [{'id':1, 'name':'building'}, {'id':2, 'name':'tree'}, {'id':3, 'name':'sky'}, {'id':4, 'name':'car'}, {'id':5, 'name':'sign'}, {'id':6, 'name':'road'}, {'id':7, 'name':'pedestrian'}, {'id':8, 'name':'fence'}, {'id':9, 'name':'pole'}, {'id':10, 'name':'sidewalk'}, {'id':11, 'name':'bicyclist'}]\n",
    "labels = [{'name':'Car', 'id':1}, {'name':'Van', 'id':2}, {'name':'Truck', 'id':3}, {'name':'Pedestrian', 'id':4},{'name':'Person_sitting', 'id':5}, {'name':'Cyclist', 'id':6}, {'name':'Tram', 'id':7}, {'name':'Misc', 'id':8}, {'name':'DontCare', 'id':9}]\n",
    "\n",
    "with open(os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME), 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd TensorFlow/models/research/object_detection/dataset_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_object_detection  subs\tTensorFlow  train_model.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-01 00:43:31.140914: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-01 00:43:31.730179: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-01 00:43:31.730217: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-01 00:43:33.335446: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-01 00:43:33.335559: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-01 00:43:33.335578: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-12-01 00:43:35.446430: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-01 00:43:35.446895: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-01 00:43:35.446923: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (user-virtual-machine): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "!python TensorFlow/models/research/object_detection/dataset_tools/create_kitti_tf_record.py \\\n",
    "        --data_dir=TensorFlow/workspace/images \\\n",
    "        --output_path=TensorFlow/workspace/annotations/kitti \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import object_detection\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': center_net {\n",
       "   num_classes: 90\n",
       "   feature_extractor {\n",
       "     type: \"hourglass_104\"\n",
       "     channel_means: 104.01361846923828\n",
       "     channel_means: 114.03422546386719\n",
       "     channel_means: 119.91659545898438\n",
       "     channel_stds: 73.60276794433594\n",
       "     channel_stds: 69.89082336425781\n",
       "     channel_stds: 70.91507720947266\n",
       "     bgr_ordering: true\n",
       "   }\n",
       "   image_resizer {\n",
       "     keep_aspect_ratio_resizer {\n",
       "       min_dimension: 1024\n",
       "       max_dimension: 1024\n",
       "       pad_to_max_dimension: true\n",
       "     }\n",
       "   }\n",
       "   object_detection_task {\n",
       "     task_loss_weight: 1.0\n",
       "     offset_loss_weight: 1.0\n",
       "     scale_loss_weight: 0.10000000149011612\n",
       "     localization_loss {\n",
       "       l1_localization_loss {\n",
       "       }\n",
       "     }\n",
       "   }\n",
       "   object_center_params {\n",
       "     object_center_loss_weight: 1.0\n",
       "     classification_loss {\n",
       "       penalty_reduced_logistic_focal_loss {\n",
       "         alpha: 2.0\n",
       "         beta: 4.0\n",
       "       }\n",
       "     }\n",
       "     min_box_overlap_iou: 0.699999988079071\n",
       "     max_box_predictions: 100\n",
       "   }\n",
       "   keypoint_label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
       "   keypoint_estimation_task {\n",
       "     task_name: \"human_pose\"\n",
       "     task_loss_weight: 1.0\n",
       "     loss {\n",
       "       localization_loss {\n",
       "         l1_localization_loss {\n",
       "         }\n",
       "       }\n",
       "       classification_loss {\n",
       "         penalty_reduced_logistic_focal_loss {\n",
       "           alpha: 2.0\n",
       "           beta: 4.0\n",
       "         }\n",
       "       }\n",
       "     }\n",
       "     keypoint_class_name: \"/m/01g317\"\n",
       "     keypoint_label_to_std {\n",
       "       key: \"left_ankle\"\n",
       "       value: 0.8899999856948853\n",
       "     }\n",
       "     keypoint_label_to_std {\n",
       "       key: \"left_ear\"\n",
       "       value: 0.3499999940395355\n",
       "     }\n",
       "     keypoint_label_to_std {\n",
       "       key: \"left_elbow\"\n",
       "       value: 0.7200000286102295\n",
       "     }\n",
       "     keypoint_label_to_std {\n",
       "       key: \"left_eye\"\n",
       "       value: 0.25\n",
       "     }\n",
       "     keypoint_label_to_std {\n",
       "       key: \"left_hip\"\n",
       "       value: 1.0700000524520874\n",
       "     }\n",
       "     keypoint_label_to_std {\n",
       "       key: \"left_knee\"\n",
       "       value: 0.8899999856948853\n",
       "     }\n",
       "     keypoint_label_to_std {\n",
       "       key: \"left_shoulder\"\n",
       "       value: 0.7900000214576721\n",
       "     }\n",
       "     keypoint_label_to_std {\n",
       "       key: \"left_wrist\"\n",
       "       value: 0.6200000047683716\n",
       "     }\n",
       "     keypoint_label_to_std {\n",
       "       key: \"nose\"\n",
       "       value: 0.25999999046325684\n",
       "     }\n",
       "     keypoint_label_to_std {\n",
       "       key: \"right_ankle\"\n",
       "       value: 0.8899999856948853\n",
       "     }\n",
       "     keypoint_label_to_std {\n",
       "       key: \"right_ear\"\n",
       "       value: 0.3499999940395355\n",
       "     }\n",
       "     keypoint_label_to_std {\n",
       "       key: \"right_elbow\"\n",
       "       value: 0.7200000286102295\n",
       "     }\n",
       "     keypoint_label_to_std {\n",
       "       key: \"right_eye\"\n",
       "       value: 0.25\n",
       "     }\n",
       "     keypoint_label_to_std {\n",
       "       key: \"right_hip\"\n",
       "       value: 1.0700000524520874\n",
       "     }\n",
       "     keypoint_label_to_std {\n",
       "       key: \"right_knee\"\n",
       "       value: 0.8899999856948853\n",
       "     }\n",
       "     keypoint_label_to_std {\n",
       "       key: \"right_shoulder\"\n",
       "       value: 0.7900000214576721\n",
       "     }\n",
       "     keypoint_label_to_std {\n",
       "       key: \"right_wrist\"\n",
       "       value: 0.6200000047683716\n",
       "     }\n",
       "     keypoint_regression_loss_weight: 0.10000000149011612\n",
       "     keypoint_heatmap_loss_weight: 1.0\n",
       "     keypoint_offset_loss_weight: 1.0\n",
       "     offset_peak_radius: 3\n",
       "     per_keypoint_offset: true\n",
       "   }\n",
       " },\n",
       " 'train_config': batch_size: 128\n",
       " data_augmentation_options {\n",
       "   random_horizontal_flip {\n",
       "     keypoint_flip_permutation: 0\n",
       "     keypoint_flip_permutation: 2\n",
       "     keypoint_flip_permutation: 1\n",
       "     keypoint_flip_permutation: 4\n",
       "     keypoint_flip_permutation: 3\n",
       "     keypoint_flip_permutation: 6\n",
       "     keypoint_flip_permutation: 5\n",
       "     keypoint_flip_permutation: 8\n",
       "     keypoint_flip_permutation: 7\n",
       "     keypoint_flip_permutation: 10\n",
       "     keypoint_flip_permutation: 9\n",
       "     keypoint_flip_permutation: 12\n",
       "     keypoint_flip_permutation: 11\n",
       "     keypoint_flip_permutation: 14\n",
       "     keypoint_flip_permutation: 13\n",
       "     keypoint_flip_permutation: 16\n",
       "     keypoint_flip_permutation: 15\n",
       "   }\n",
       " }\n",
       " data_augmentation_options {\n",
       "   random_adjust_hue {\n",
       "   }\n",
       " }\n",
       " data_augmentation_options {\n",
       "   random_adjust_contrast {\n",
       "   }\n",
       " }\n",
       " data_augmentation_options {\n",
       "   random_adjust_saturation {\n",
       "   }\n",
       " }\n",
       " data_augmentation_options {\n",
       "   random_adjust_brightness {\n",
       "   }\n",
       " }\n",
       " data_augmentation_options {\n",
       "   random_square_crop_by_scale {\n",
       "     scale_min: 0.6000000238418579\n",
       "     scale_max: 1.2999999523162842\n",
       "   }\n",
       " }\n",
       " optimizer {\n",
       "   adam_optimizer {\n",
       "     learning_rate {\n",
       "       cosine_decay_learning_rate {\n",
       "         learning_rate_base: 0.0010000000474974513\n",
       "         total_steps: 250000\n",
       "         warmup_learning_rate: 0.0002500000118743628\n",
       "         warmup_steps: 5000\n",
       "       }\n",
       "     }\n",
       "     epsilon: 1.0000000116860974e-07\n",
       "   }\n",
       "   use_moving_average: false\n",
       " }\n",
       " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
       " num_steps: 250000\n",
       " max_number_of_boxes: 100\n",
       " unpad_groundtruth_tensors: false\n",
       " fine_tune_checkpoint_type: \"detection\"\n",
       " fine_tune_checkpoint_version: V2,\n",
       " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\"\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED/train2017-?????-of-00256.tfrecord\"\n",
       " }\n",
       " num_keypoints: 17,\n",
       " 'eval_config': num_visualizations: 10\n",
       " metrics_set: \"coco_detection_metrics\"\n",
       " use_moving_averages: false\n",
       " min_score_threshold: 0.20000000298023224\n",
       " max_num_boxes_to_visualize: 20\n",
       " batch_size: 1\n",
       " parameterized_metric {\n",
       "   coco_keypoint_metrics {\n",
       "     class_label: \"person\"\n",
       "     keypoint_label_to_sigmas {\n",
       "       key: \"left_ankle\"\n",
       "       value: 0.08900000154972076\n",
       "     }\n",
       "     keypoint_label_to_sigmas {\n",
       "       key: \"left_ear\"\n",
       "       value: 0.03500000014901161\n",
       "     }\n",
       "     keypoint_label_to_sigmas {\n",
       "       key: \"left_elbow\"\n",
       "       value: 0.07199999690055847\n",
       "     }\n",
       "     keypoint_label_to_sigmas {\n",
       "       key: \"left_eye\"\n",
       "       value: 0.02500000037252903\n",
       "     }\n",
       "     keypoint_label_to_sigmas {\n",
       "       key: \"left_hip\"\n",
       "       value: 0.10700000077486038\n",
       "     }\n",
       "     keypoint_label_to_sigmas {\n",
       "       key: \"left_knee\"\n",
       "       value: 0.08699999749660492\n",
       "     }\n",
       "     keypoint_label_to_sigmas {\n",
       "       key: \"left_shoulder\"\n",
       "       value: 0.07900000363588333\n",
       "     }\n",
       "     keypoint_label_to_sigmas {\n",
       "       key: \"left_wrist\"\n",
       "       value: 0.06199999898672104\n",
       "     }\n",
       "     keypoint_label_to_sigmas {\n",
       "       key: \"nose\"\n",
       "       value: 0.026000000536441803\n",
       "     }\n",
       "     keypoint_label_to_sigmas {\n",
       "       key: \"right_ankle\"\n",
       "       value: 0.08900000154972076\n",
       "     }\n",
       "     keypoint_label_to_sigmas {\n",
       "       key: \"right_ear\"\n",
       "       value: 0.03500000014901161\n",
       "     }\n",
       "     keypoint_label_to_sigmas {\n",
       "       key: \"right_elbow\"\n",
       "       value: 0.07199999690055847\n",
       "     }\n",
       "     keypoint_label_to_sigmas {\n",
       "       key: \"right_eye\"\n",
       "       value: 0.02500000037252903\n",
       "     }\n",
       "     keypoint_label_to_sigmas {\n",
       "       key: \"right_hip\"\n",
       "       value: 0.10700000077486038\n",
       "     }\n",
       "     keypoint_label_to_sigmas {\n",
       "       key: \"right_knee\"\n",
       "       value: 0.08699999749660492\n",
       "     }\n",
       "     keypoint_label_to_sigmas {\n",
       "       key: \"right_shoulder\"\n",
       "       value: 0.07900000363588333\n",
       "     }\n",
       "     keypoint_label_to_sigmas {\n",
       "       key: \"right_wrist\"\n",
       "       value: 0.06199999898672104\n",
       "     }\n",
       "   }\n",
       " }\n",
       " keypoint_edge {\n",
       "   start: 0\n",
       "   end: 1\n",
       " }\n",
       " keypoint_edge {\n",
       "   start: 0\n",
       "   end: 2\n",
       " }\n",
       " keypoint_edge {\n",
       "   start: 1\n",
       "   end: 3\n",
       " }\n",
       " keypoint_edge {\n",
       "   start: 2\n",
       "   end: 4\n",
       " }\n",
       " keypoint_edge {\n",
       "   start: 0\n",
       "   end: 5\n",
       " }\n",
       " keypoint_edge {\n",
       "   start: 0\n",
       "   end: 6\n",
       " }\n",
       " keypoint_edge {\n",
       "   start: 5\n",
       "   end: 7\n",
       " }\n",
       " keypoint_edge {\n",
       "   start: 7\n",
       "   end: 9\n",
       " }\n",
       " keypoint_edge {\n",
       "   start: 6\n",
       "   end: 8\n",
       " }\n",
       " keypoint_edge {\n",
       "   start: 8\n",
       "   end: 10\n",
       " }\n",
       " keypoint_edge {\n",
       "   start: 5\n",
       "   end: 6\n",
       " }\n",
       " keypoint_edge {\n",
       "   start: 5\n",
       "   end: 11\n",
       " }\n",
       " keypoint_edge {\n",
       "   start: 6\n",
       "   end: 12\n",
       " }\n",
       " keypoint_edge {\n",
       "   start: 11\n",
       "   end: 12\n",
       " }\n",
       " keypoint_edge {\n",
       "   start: 11\n",
       "   end: 13\n",
       " }\n",
       " keypoint_edge {\n",
       "   start: 13\n",
       "   end: 15\n",
       " }\n",
       " keypoint_edge {\n",
       "   start: 12\n",
       "   end: 14\n",
       " }\n",
       " keypoint_edge {\n",
       "   start: 14\n",
       "   end: 16\n",
       " },\n",
       " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED/val2017-?????-of-00032.tfrecord\"\n",
       " }\n",
       " num_keypoints: 17\n",
       " ],\n",
       " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED/label_map.txt\"\n",
       " shuffle: false\n",
       " num_epochs: 1\n",
       " tf_record_input_reader {\n",
       "   input_path: \"PATH_TO_BE_CONFIGURED/val2017-?????-of-00032.tfrecord\"\n",
       " }\n",
       " num_keypoints: 17}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:\n",
    "    proto_str = f.read()\n",
    "    text_format.Merge(proto_str, pipeline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "pipeline_config.train_config.batch_size = 100\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0.index')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'kitti_train.tfrecord')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'kitti_val.tfrecord')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:\n",
    "    f.write(config_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=10000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python TensorFlow/models/research/object_detection/model_main_tf2.py --model_dir=TensorFlow/workspace/models/centernet_hourglass104 --pipeline_config_path=TensorFlow/workspace/models/centernet_hourglass104/pipeline.config --num_train_steps=10000\n"
     ]
    }
   ],
   "source": [
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TensorFlow/workspace/models/centernet_hourglass104/pipeline.config'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files['PIPELINE_CONFIG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-03 11:26:58.194512: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-03 11:26:58.194550: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/user/anaconda3/envs/tf2od/lib/python3.9/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/home/user/anaconda3/envs/tf2od/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/home/user/anaconda3/envs/tf2od/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl5mutexC1Ev']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/home/user/anaconda3/envs/tf2od/lib/python3.9/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/home/user/anaconda3/envs/tf2od/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/home/user/anaconda3/envs/tf2od/lib/python3.9/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZNK10tensorflow4data11DatasetBase8FinalizeEPNS_15OpKernelContextESt8functionIFN3tsl8StatusOrISt10unique_ptrIS1_NS5_4core15RefCountDeleterEEEEvEE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n",
      "2022-12-03 11:27:00.867682: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/user/anaconda3/envs/tf2od/lib/python3.9/site-packages/cv2/../../lib64:\n",
      "2022-12-03 11:27:00.867718: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-03 11:27:00.867735: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (user-virtual-machine): /proc/driver/nvidia/version does not exist\n",
      "2022-12-03 11:27:00.869123: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "W1203 11:27:00.870483 139732223484160 cross_device_ops.py:1386] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "I1203 11:27:00.878285 139732223484160 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 10000\n",
      "I1203 11:27:00.881649 139732223484160 config_util.py:552] Maybe overwriting train_steps: 10000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I1203 11:27:00.881761 139732223484160 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/Desktop/project/TensorFlow/models/research/object_detection/model_main_tf2.py\", line 114, in <module>\n",
      "    tf.compat.v1.app.run()\n",
      "  File \"/home/user/anaconda3/envs/tf2od/lib/python3.9/site-packages/tensorflow/python/platform/app.py\", line 36, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/home/user/anaconda3/envs/tf2od/lib/python3.9/site-packages/absl/app.py\", line 308, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/home/user/anaconda3/envs/tf2od/lib/python3.9/site-packages/absl/app.py\", line 254, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"/home/user/Desktop/project/TensorFlow/models/research/object_detection/model_main_tf2.py\", line 105, in main\n",
      "    model_lib_v2.train_loop(\n",
      "  File \"/home/user/anaconda3/envs/tf2od/lib/python3.9/site-packages/object_detection/model_lib_v2.py\", line 547, in train_loop\n",
      "    detection_model = MODEL_BUILD_UTIL_MAP['detection_model_fn_base'](\n",
      "  File \"/home/user/anaconda3/envs/tf2od/lib/python3.9/site-packages/object_detection/builders/model_builder.py\", line 1262, in build\n",
      "    return build_func(getattr(model_config, meta_architecture), is_training,\n",
      "  File \"/home/user/anaconda3/envs/tf2od/lib/python3.9/site-packages/object_detection/builders/model_builder.py\", line 412, in _build_ssd_model\n",
      "    _check_feature_extractor_exists(ssd_config.feature_extractor.type)\n",
      "  File \"/home/user/anaconda3/envs/tf2od/lib/python3.9/site-packages/object_detection/builders/model_builder.py\", line 270, in _check_feature_extractor_exists\n",
      "    raise ValueError(\n",
      "ValueError:  is not supported for tf version 2. See `model_builder.py` for features extractors compatible with different versions of Tensorflow\n"
     ]
    }
   ],
   "source": [
    "!python TensorFlow/models/research/object_detection/model_main_tf2.py --model_dir=TensorFlow/workspace/models/centernet_hourglass104 --pipeline_config_path=TensorFlow/workspace/models/centernet_hourglass104/pipeline.config --num_train_steps=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2od",
   "language": "python",
   "name": "tf2od"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
